{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLAOIV: Many Weak Instruments\n",
        "\n",
        "This notebook compares different ML methods for MLAOIV construction in the many-weak-instruments setting.\n",
        "\n",
        "We compare:\n",
        "- LassoCV\n",
        "- RidgeCV  \n",
        "- ElasticNetCV\n",
        "- KernelRidge\n",
        "- MLP (Neural Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from linearmodels.iv import IV2SLS\n",
        "from joblib import Parallel, delayed\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core functions\n",
        "def simulate_iv_data(n_obs, n_instruments, error_covariance=None, \n",
        "                      instrument_strength=0.5, seed=None):\n",
        "    \"\"\"Simulate data for IV regression with many weak instruments.\"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    if error_covariance is None:\n",
        "        error_covariance = np.array([[1, 0.5], [0.5, 1]])\n",
        "    \n",
        "    errors = np.random.multivariate_normal([0, 0], error_covariance, n_obs)\n",
        "    u, e = errors[:, 0], errors[:, 1]\n",
        "    \n",
        "    Z = np.random.normal(0, 1, (n_obs, n_instruments))\n",
        "    pi = np.ones(n_instruments)\n",
        "    scale = (50 / n_instruments) * instrument_strength\n",
        "    \n",
        "    y1 = 0.3 + scale * (Z @ pi) + u\n",
        "    y2 = -0.9 + 0.75 * y1 + e\n",
        "    \n",
        "    return {'Z': Z, 'y1': y1, 'y2': y2}\n",
        "\n",
        "\n",
        "def compute_mlaoiv(Z, y_endog, regressor, cv_folds=3):\n",
        "    \"\"\"Compute MLAOIV using cross-validated predictions.\"\"\"\n",
        "    return cross_val_predict(regressor, Z, y_endog, cv=cv_folds)\n",
        "\n",
        "\n",
        "def estimate_iv2sls(y_outcome, y_endog, mlaoiv_instrument):\n",
        "    \"\"\"Estimate IV-2SLS using MLAOIV instrument.\"\"\"\n",
        "    df = pd.DataFrame({'y2': y_outcome, 'y1': y_endog, 'mlaoiv': mlaoiv_instrument})\n",
        "    model = IV2SLS.from_formula(\"y2 ~ 1 + [y1 ~ mlaoiv]\", data=df).fit()\n",
        "    return {'params': np.array(model.params), 'std_errors': np.array(model.std_errors)}\n",
        "\n",
        "\n",
        "def get_regressors():\n",
        "    \"\"\"Return dictionary of ML regressors to compare.\"\"\"\n",
        "    alphas = [2000, 1000, 100, 50, 10, 1, 0.1]\n",
        "    return {\n",
        "        'Lasso': LassoCV(cv=4, alphas=alphas, max_iter=10000),\n",
        "        'Ridge': RidgeCV(cv=4, alphas=alphas),\n",
        "        'ElasticNet': ElasticNetCV(cv=4, l1_ratio=[0.1, 0.5, 0.9], \n",
        "                                   alphas=alphas, max_iter=10000),\n",
        "        'KernelRidge': KernelRidge(alpha=1.0),\n",
        "        'MLP': MLPRegressor(hidden_layer_sizes=(64,), alpha=1e-4, \n",
        "                           max_iter=1000, random_state=42)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Single Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate data\n",
        "n_obs = 1000\n",
        "n_instruments = 500\n",
        "true_beta = 0.75\n",
        "\n",
        "data = simulate_iv_data(n_obs, n_instruments, instrument_strength=0.5, seed=42)\n",
        "\n",
        "# Compare all methods\n",
        "results = []\n",
        "for name, regr in get_regressors().items():\n",
        "    mlaoiv = compute_mlaoiv(data['Z'], data['y1'], regressor=regr, cv_folds=3)\n",
        "    est = estimate_iv2sls(data['y2'], data['y1'], mlaoiv)\n",
        "    results.append({\n",
        "        'Method': name,\n",
        "        'Beta Est': est['params'][1],\n",
        "        'Beta SE': est['std_errors'][1],\n",
        "        'Bias': est['params'][1] - true_beta\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"=== Method Comparison (n=1000, d=500) ===\")\n",
        "print(df_results.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monte Carlo Simulation\n",
        "\n",
        "Compare methods across multiple simulation runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_single_sim(seed, regressor, n_obs=1000, n_instruments=500, mu=0.5, rho=0.5):\n",
        "    \"\"\"Run single simulation.\"\"\"\n",
        "    error_cov = np.array([[1, rho], [rho, 1]])\n",
        "    data = simulate_iv_data(n_obs, n_instruments, error_cov, mu, seed)\n",
        "    mlaoiv = compute_mlaoiv(data['Z'], data['y1'], regressor, cv_folds=3)\n",
        "    return estimate_iv2sls(data['y2'], data['y1'], mlaoiv)\n",
        "\n",
        "\n",
        "def mc_simulation(regressor_name, regressor, n_sims=20, **kwargs):\n",
        "    \"\"\"Run Monte Carlo simulation for a given regressor.\"\"\"\n",
        "    results = Parallel(n_jobs=-1)(\n",
        "        delayed(run_single_sim)(seed, regressor, **kwargs) \n",
        "        for seed in range(n_sims)\n",
        "    )\n",
        "    params = np.array([r['params'] for r in results])\n",
        "    true_beta = 0.75\n",
        "    \n",
        "    return {\n",
        "        'Method': regressor_name,\n",
        "        'Mean Beta': np.mean(params[:, 1]),\n",
        "        'Bias': np.mean(params[:, 1]) - true_beta,\n",
        "        'Std': np.std(params[:, 1]),\n",
        "        'RMSE': np.sqrt(np.mean((params[:, 1] - true_beta)**2))\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run Monte Carlo for each method\n",
        "n_sims = 20\n",
        "print(f\"Running {n_sims} simulations for each method...\")\n",
        "\n",
        "mc_results = []\n",
        "for name, regr in get_regressors().items():\n",
        "    print(f\"  {name}...\")\n",
        "    mc_results.append(mc_simulation(name, regr, n_sims=n_sims))\n",
        "\n",
        "df_mc = pd.DataFrame(mc_results)\n",
        "print(\"\\n=== Monte Carlo Results (n=1000, d=500, 20 sims) ===\")\n",
        "print(df_mc.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Varying Instrument Strengthw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare across different instrument strengths\n",
        "mu_values = [0.3, 0.5, 0.7]\n",
        "ridge = RidgeCV(cv=4, alphas=[2000, 1000, 100, 50, 10, 1, 0.1])\n",
        "\n",
        "strength_results = []\n",
        "for mu in mu_values:\n",
        "    print(f\"Running simulations for μ={mu}...\")\n",
        "    result = mc_simulation('Ridge', ridge, n_sims=20, mu=mu)\n",
        "    result['μ'] = mu\n",
        "    strength_results.append(result)\n",
        "\n",
        "df_strength = pd.DataFrame(strength_results)\n",
        "print(\"\\n=== Ridge MLAOIV by Instrument Strength ===\")\n",
        "print(df_strength[['μ', 'Mean Beta', 'Bias', 'Std', 'RMSE']].to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
