{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLAOIV: Many Weak Instruments\n",
        "\n",
        "This notebook demonstrates Machine Learning Approximate Optimal Instrumental Variables (MLAOIV) in a many-weak-instruments setting.\n",
        "\n",
        "## Model\n",
        "\n",
        "We consider a standard IV setup with $d=500$ instruments:\n",
        "- **First stage**: $y_1 = \\alpha + \\pi' Z + u$\n",
        "- **Structural equation**: $y_2 = \\gamma + \\beta y_1 + e$\n",
        "\n",
        "where $(u, e)$ are correlated (œÅ=0.5), creating endogeneity.\n",
        "\n",
        "## MLAOIV Approach\n",
        "\n",
        "Instead of using all instruments directly, we construct the optimal IV as $\\hat{E}[y_1 | Z]$ using ML methods with cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV, LinearRegression\n",
        "from linearmodels.iv import IV2SLS\n",
        "from joblib import Parallel, delayed\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_iv_data(n_obs, n_instruments, error_covariance=None, \n",
        "                      instrument_strength=0.5, true_beta=0.75, \n",
        "                      true_intercept=-0.9, seed=None):\n",
        "    \"\"\"\n",
        "    Simulate data for IV regression.\n",
        "    \n",
        "    Model:\n",
        "        y1 = 0.3 + pi * Z + u  (first stage)\n",
        "        y2 = intercept + beta * y1 + e  (structural)\n",
        "        where (u, e) ~ N(0, error_covariance)\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    if error_covariance is None:\n",
        "        error_covariance = np.array([[1, 0.5], [0.5, 1]])\n",
        "    \n",
        "    # Generate errors\n",
        "    errors = np.random.multivariate_normal([0, 0], error_covariance, n_obs)\n",
        "    u, e = errors[:, 0], errors[:, 1]\n",
        "    \n",
        "    # Generate instruments\n",
        "    Z = np.random.normal(0, 1, (n_obs, n_instruments))\n",
        "    \n",
        "    # All instruments are relevant with equal weight\n",
        "    pi = np.ones(n_instruments)\n",
        "    scale = (50 / n_instruments) * instrument_strength\n",
        "    \n",
        "    # Generate variables\n",
        "    y1 = 0.3 + scale * (Z @ pi) + u\n",
        "    y2 = true_intercept + true_beta * y1 + e\n",
        "    \n",
        "    return {'Z': Z, 'y1': y1, 'y2': y2}\n",
        "\n",
        "\n",
        "def compute_mlaoiv(Z, y_endog, regressor, cv_folds=3):\n",
        "    \"\"\"\n",
        "    Compute MLAOIV using cross-validated predictions.\n",
        "    \n",
        "    Parameters:\n",
        "        Z: instrument matrix (n x d)\n",
        "        y_endog: endogenous variable\n",
        "        regressor: sklearn estimator (e.g., RidgeCV, LassoCV)\n",
        "        cv_folds: number of CV folds for prediction\n",
        "    \"\"\"\n",
        "    return cross_val_predict(regressor, Z, y_endog, cv=cv_folds)\n",
        "\n",
        "\n",
        "def estimate_iv2sls(y_outcome, y_endog, mlaoiv_instrument):\n",
        "    \"\"\"Estimate IV-2SLS using MLAOIV instrument.\"\"\"\n",
        "    df = pd.DataFrame({'y2': y_outcome, 'y1': y_endog, 'mlaoiv': mlaoiv_instrument})\n",
        "    model = IV2SLS.from_formula(\"y2 ~ 1 + [y1 ~ mlaoiv]\", data=df).fit()\n",
        "    return {'params': np.array(model.params), 'std_errors': np.array(model.std_errors), 'model': model}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Single Simulation Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample size: 1000\n",
            "Number of instruments: 500\n",
            "True beta: 0.75\n",
            "True intercept: -0.9\n"
          ]
        }
      ],
      "source": [
        "# Simulation parameters\n",
        "n_obs = 1000\n",
        "n_instruments = 500\n",
        "error_covariance = np.array([[1, 0.5], [0.5, 1]])\n",
        "\n",
        "# True parameters\n",
        "true_beta = 0.75\n",
        "true_intercept = -0.9\n",
        "\n",
        "print(f\"Sample size: {n_obs}\")\n",
        "print(f\"Number of instruments: {n_instruments}\")\n",
        "print(f\"True beta: {true_beta}\")\n",
        "print(f\"True intercept: {true_intercept}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Z shape: (1000, 500)\n",
            "y1 shape: (1000,)\n",
            "y2 shape: (1000,)\n"
          ]
        }
      ],
      "source": [
        "# Generate data\n",
        "data = simulate_iv_data(\n",
        "    n_obs=n_obs,\n",
        "    n_instruments=n_instruments,\n",
        "    error_covariance=error_covariance,\n",
        "    instrument_strength=0.5,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(f\"Z shape: {data['Z'].shape}\")\n",
        "print(f\"y1 shape: {data['y1'].shape}\")\n",
        "print(f\"y2 shape: {data['y2'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLAOIV instrument computed. Shape: (1000,)\n",
            "Correlation with y1: 0.5002\n"
          ]
        }
      ],
      "source": [
        "# Compute MLAOIV using Ridge regression\n",
        "ridge = RidgeCV(cv=4, alphas=[2000, 1000, 100, 50, 10, 1, 0.1])\n",
        "\n",
        "mlaoiv = compute_mlaoiv(\n",
        "    Z=data['Z'],\n",
        "    y_endog=data['y1'],\n",
        "    regressor=ridge,\n",
        "    cv_folds=3\n",
        ")\n",
        "\n",
        "print(f\"MLAOIV instrument computed. Shape: {mlaoiv.shape}\")\n",
        "print(f\"Correlation with y1: {np.corrcoef(mlaoiv, data['y1'])[0,1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MLAOIV Estimation Results ===\n",
            "                          IV-2SLS Estimation Summary                          \n",
            "==============================================================================\n",
            "Dep. Variable:                     y2   R-squared:                      0.6356\n",
            "Estimator:                    IV-2SLS   Adj. R-squared:                 0.6353\n",
            "No. Observations:                1000   F-statistic:                    260.99\n",
            "Date:                Sun, Jan 18 2026   P-value (F-stat)                0.0000\n",
            "Time:                        23:10:45   Distribution:                  chi2(1)\n",
            "Cov. Estimator:                robust                                         \n",
            "                                                                              \n",
            "                             Parameter Estimates                              \n",
            "==============================================================================\n",
            "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------\n",
            "Intercept     -0.8915     0.0334    -26.707     0.0000     -0.9569     -0.8261\n",
            "y1             0.7073     0.0438     16.155     0.0000      0.6215      0.7932\n",
            "==============================================================================\n",
            "\n",
            "Endogenous: y1\n",
            "Instruments: mlaoiv\n",
            "Robust Covariance (Heteroskedastic)\n",
            "Debiased: False\n"
          ]
        }
      ],
      "source": [
        "# Estimate IV-2SLS\n",
        "results = estimate_iv2sls(\n",
        "    y_outcome=data['y2'],\n",
        "    y_endog=data['y1'],\n",
        "    mlaoiv_instrument=mlaoiv\n",
        ")\n",
        "\n",
        "print(\"\\n=== MLAOIV Estimation Results ===\")\n",
        "print(results['model'].summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== OLS vs MLAOIV ===\n",
            "Method       Intercept    Beta         Beta Bias   \n",
            "------------------------------------------------\n",
            "OLS          -0.9410      0.9481       0.1981      \n",
            "MLAOIV       -0.8915      0.7073       -0.0427     \n",
            "True         -0.9000      0.7500       0.0000      \n"
          ]
        }
      ],
      "source": [
        "# OLS (biased due to endogeneity)\n",
        "X_ols = np.column_stack([np.ones(n_obs), data['y1']])\n",
        "ols_beta = np.linalg.lstsq(X_ols, data['y2'], rcond=None)[0]\n",
        "\n",
        "print(\"=== OLS vs MLAOIV ===\")\n",
        "print(f\"{'Method':<12} {'Intercept':<12} {'Beta':<12} {'Beta Bias':<12}\")\n",
        "print(\"-\" * 48)\n",
        "print(f\"{'OLS':<12} {ols_beta[0]:<12.4f} {ols_beta[1]:<12.4f} {ols_beta[1] - true_beta:<12.4f}\")\n",
        "print(f\"{'MLAOIV':<12} {results['params'][0]:<12.4f} {results['params'][1]:<12.4f} {results['params'][1] - true_beta:<12.4f}\")\n",
        "print(f\"{'True':<12} {true_intercept:<12.4f} {true_beta:<12.4f} {0.0:<12.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Compare Different ML Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Method Comparison ===\n",
            "    Method  Beta Est  Beta SE  Beta Bias\n",
            "     Lasso  0.455085 0.210854  -0.294915\n",
            "     Ridge  0.707349 0.043785  -0.042651\n",
            "ElasticNet  0.830271 0.343409   0.080271\n"
          ]
        }
      ],
      "source": [
        "# Compare Lasso, Ridge, and ElasticNet\n",
        "regressors = {\n",
        "    'Lasso': LassoCV(cv=4, alphas=[2000, 1000, 100, 50, 10, 1, 0.1], max_iter=10000),\n",
        "    'Ridge': RidgeCV(cv=4, alphas=[2000, 1000, 100, 50, 10, 1, 0.1]),\n",
        "    'ElasticNet': ElasticNetCV(cv=4, l1_ratio=[0.1, 0.5, 0.9], \n",
        "                               alphas=[2000, 1000, 100, 50, 10], max_iter=10000)\n",
        "}\n",
        "\n",
        "results_list = []\n",
        "for name, regr in regressors.items():\n",
        "    mlaoiv = compute_mlaoiv(data['Z'], data['y1'], regressor=regr, cv_folds=3)\n",
        "    est = estimate_iv2sls(data['y2'], data['y1'], mlaoiv)\n",
        "    results_list.append({\n",
        "        'Method': name,\n",
        "        'Beta Est': est['params'][1],\n",
        "        'Beta SE': est['std_errors'][1],\n",
        "        'Beta Bias': est['params'][1] - true_beta\n",
        "    })\n",
        "\n",
        "comparison = pd.DataFrame(results_list)\n",
        "print(\"\\n=== Method Comparison ===\")\n",
        "print(comparison.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Monte Carlo Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running 20 Monte Carlo simulations...\n",
            "\n",
            "=== Monte Carlo Results (Ridge MLAOIV) ===\n",
            "Parameter    Bias         Avg SE       RMSE        \n",
            "------------------------------------------------\n",
            "Intercept    -0.0038      0.0338       0.0356      \n",
            "Beta         0.0111       0.0407       0.0451      \n"
          ]
        }
      ],
      "source": [
        "def single_simulation(seed):\n",
        "    \"\"\"Run a single simulation and return results.\"\"\"\n",
        "    data = simulate_iv_data(\n",
        "        n_obs=1000,\n",
        "        n_instruments=500,\n",
        "        error_covariance=np.array([[1, 0.5], [0.5, 1]]),\n",
        "        instrument_strength=0.5,\n",
        "        seed=seed\n",
        "    )\n",
        "    ridge = RidgeCV(cv=4, alphas=[2000, 1000, 100, 50, 10, 1, 0.1])\n",
        "    mlaoiv = compute_mlaoiv(data['Z'], data['y1'], regressor=ridge, cv_folds=3)\n",
        "    results = estimate_iv2sls(data['y2'], data['y1'], mlaoiv)\n",
        "    return {'params': results['params'], 'std_errors': results['std_errors']}\n",
        "\n",
        "# Run 20 simulations in parallel\n",
        "n_sims = 20\n",
        "print(f\"Running {n_sims} Monte Carlo simulations...\")\n",
        "mc_results = Parallel(n_jobs=-1)(\n",
        "    delayed(single_simulation)(seed) for seed in range(n_sims)\n",
        ")\n",
        "\n",
        "# Aggregate results\n",
        "params_matrix = np.array([r['params'] for r in mc_results])\n",
        "se_matrix = np.array([r['std_errors'] for r in mc_results])\n",
        "\n",
        "true_params = np.array([true_intercept, true_beta])\n",
        "\n",
        "bias = np.mean(params_matrix - true_params, axis=0)\n",
        "avg_se = np.mean(se_matrix, axis=0)\n",
        "rmse = np.sqrt(np.mean((params_matrix - true_params)**2, axis=0))\n",
        "\n",
        "print(\"\\n=== Monte Carlo Results (Ridge MLAOIV) ===\")\n",
        "print(f\"{'Parameter':<12} {'Bias':<12} {'Avg SE':<12} {'RMSE':<12}\")\n",
        "print(\"-\" * 48)\n",
        "print(f\"{'Intercept':<12} {bias[0]:<12.4f} {avg_se[0]:<12.4f} {rmse[0]:<12.4f}\")\n",
        "print(f\"{'Beta':<12} {bias[1]:<12.4f} {avg_se[1]:<12.4f} {rmse[1]:<12.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bond310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
